#!/bin/bash

cd spark/dist/

bin/spark-submit \
  --deploy-mode cluster \
  --master k8s://http://127.0.0.1:8001 \
  --conf spark.executor.instances=2 \
  --conf spark.app.name=spark-streaming \
  --conf spark.kubernetes.driver.docker.image=kubespark/spark-driver-py:v2.2.0-kubernetes-0.5.0 \
  --conf spark.kubernetes.executor.docker.image=kubespark/spark-executor-py:v2.2.0-kubernetes-0.5.0 \
  --conf spark.kubernetes.initcontainer.docker.image=kubespark/spark-init:v2.2.0-kubernetes-0.5.0 \
  --conf spark.kubernetes.resourceStagingServer.uri=http://192.168.64.14:31000 \
  --jars local:///opt/spark/examples/jars/spark-examples_2.11-2.2.0-k8s-0.5.0.jar \
  --packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0 \
  local:///opt/spark/examples/src/main/python/streaming/kafka_wordcount.py zk-0.zk-svc.default.svc.cluster.local:2181 test