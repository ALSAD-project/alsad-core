version: '3.4'

services:
  jupyter:
    image: jupyter/all-spark-notebook:279b14bbdda3
    volumes:
      - .:/home/jovyan/alsad-core:ro
    ports:
      - "8888:8888"

  spark:
    image:  alsad/spark:2.1.0-2.2.0-1-hadoop-2.7

  alsad-dev:
      build:
        context: .
        dockerfile: ./dockerfiles/godev.dockerfile
      image: localhost/godev:1.9-alpine
      working_dir: /go/src/github.com/ALSAD-project/alsad-core
      volumes:
        - .:/go/src/github.com/ALSAD-project/alsad-core

  dispatcher:
    image: alsad/dispatcher:git-9695aa3
    depends_on:
      - redis
    networks:
      - faas
    volumes:
      - fsq-store:/var/run/alsad-dispatcher/fsq
    environment:
      DP_ENTER_MODE: "training" # can be "detect", "feedback"
      DP_FSQ_REDIS_ADDR: "redis:6379"
      DP_FSQ_DIR: "/var/run/alsad-dispatcher/fsq"
      DP_FSQ_EXPERT_INPUT_QUEUE: "expert-input-queue"
      DP_FSQ_EXPERT_OUTPUT_QUEUE: "expert-output-queue"
      DP_FEEDER_URL: "http://alsad_gateway:8080/function/feeder"
      DP_BA_URL: "http://alsad_gateway:8080/function/ba"
      DP_USL_URL: "http://alsad_gateway:8080/function/usl"
      DP_SL_URL: "http://alsad_gateway:8080/function/sl"

  expertsystem-daemon:
    build:
      context: .
      dockerfile: ./dockerfiles/expertsystem.daemon.dockerfile
    image: localhost/expertsystem
    environment:
      - PORT=4000
      - HOSTNAME=0.0.0.0
      - SOURCE_DIRECTORY=tmp/input/
      - DESTINATION_DIRECTORY=tmp/input/
    ports:
      - "4000:4000"

  expertsystem-terminal:
    build:
      context: .
      dockerfile: ./dockerfiles/expertsystem.terminal.dockerfile
    image: localhost/expertsystem
    environment:
      - PORT=4000
      - HOSTNAME=expertsystem-daemon
      - SOURCE_DIRECTORY=tmp/input/
      - DESTINATION_DIRECTORY=tmp/input/

  redis:
    image: redis:4.0-alpine
    networks:
      - faas
    volumes:
      - redis-store:/data

volumes:
  expert-db:
  redis-store:
  fsq-store:

networks:
  faas:
    external:
      name: alsad_faas
